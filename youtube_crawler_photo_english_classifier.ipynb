{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "# !pip install gputil\n",
    "# try:\n",
    "#   import GPUtil as GPU\n",
    "#   GPUs = GPU.getGPUs()\n",
    "#   device='/gpu:0'\n",
    "# except:\n",
    "#   device='/cpu:0'\n",
    "\n",
    "# import os\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "\n",
    "# ##出現提示欄進行授權\n",
    "\n",
    "# os.chdir('/content/drive/Shareddrives/專題') #切換該目錄\n",
    "# os.listdir() #確認目錄內容\n",
    "# !pip install zhon\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re \n",
    "import cv2\n",
    "import keras\n",
    "import keras.utils\n",
    "from keras import utils as np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import cifar10 #匯入cifar10資料集\n",
    "import numpy as np #匯入numpy模組\n",
    "np.random.seed(10) #設定seed\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential  #匯入Sequential模組\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D  #匯入layers模組\n",
    "from keras.layers import ZeroPadding2D,Activation  #匯入layers模組\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, concatenate,Embedding,Layer,Multiply \n",
    "import tensorflow as tf\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.recurrent import LSTM\n",
    "from sklearn.metrics import accuracy_score\n",
    "from zhon.hanzi import punctuation\n",
    "import jieba\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow.keras.backend as K\n",
    "from keras import metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import random\n",
    "np.random.seed(10)\n",
    "from sklearn.utils import shuffle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(attention,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        self.W=self.add_weight(name=\"att_weight\",shape=(input_shape[-1],1),initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\",shape=(input_shape[1],1),initializer=\"zeros\")        \n",
    "        super(attention, self).build(input_shape)\n",
    "\n",
    "    def call(self,x):\n",
    "        et=K.squeeze(K.tanh(K.dot(x,self.W)+self.b),axis=-1)\n",
    "        at=K.softmax(et)\n",
    "        at=K.expand_dims(at,axis=-1)\n",
    "        output=x*at\n",
    "        return K.sum(output,axis=1)\n",
    "\n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return (input_shape[0],input_shape[-1])\n",
    "\n",
    "    def get_config(self):\n",
    "        return super(attention,self).get_config()\n",
    "\n",
    "def get_dataset_partitions_tf(dsx, dsy, ds_size):\n",
    "    #assert (train_split + test_split + val_split) == 1\n",
    "    \n",
    "        # Specify seed to always have the same split distribution between runs\n",
    "    dsx, dsy=shuffle(dsx, dsy)\n",
    "\n",
    "    train_size = int(0.65* ds_size)\n",
    "    val_size = int(0.1 * ds_size)\n",
    "    \n",
    "\n",
    "    train_dsx = dsx[:train_size]\n",
    "    val_dsx = dsx[train_size:val_size]\n",
    "    test_dsx = dsx[val_size:]\n",
    "    \n",
    "    train_dsy = dsy[:train_size]\n",
    "    val_dsy = dsy[train_size:val_size]\n",
    "    test_dsy = dsy[val_size:]\n",
    "    \n",
    "#     train_ds = ds.take(train_size)\n",
    "#     val_ds = ds.skip(train_size).take(val_size)\n",
    "#     test_ds = ds.skip(train_size).skip(val_size)\n",
    "    \n",
    "    return train_dsx, val_dsx, test_dsx, train_dsy, val_dsy, test_dsy\n",
    "\n",
    "X = pd.read_csv(\"concat_data_english.csv\",encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "viewcount=X[\"classifier_2\"]\n",
    "# viewcount=X.iloc[:,6:]\n",
    "\n",
    "\n",
    "#photo\n",
    "\n",
    "y = X.iloc[0:,1]\n",
    "y = list(y)\n",
    "pic_id = X.iloc[:,2:3]\n",
    "# example of loading an image with the Keras API\n",
    "\n",
    "##定義ImageDataGenerator\n",
    "img_gen = ImageDataGenerator( featurewise_center=True,featurewise_std_normalization=True,rotation_range=10,width_shift_range=0.1,\n",
    "                                            height_shift_range=0.1,shear_range=0.1,zoom_range=0.1,horizontal_flip=True,vertical_flip=False,dtype=np.float32)\n",
    "width = 480\n",
    "height = 360\n",
    "batch_size = 2\n",
    "\n",
    "\n",
    "# load the image\n",
    "# import torch\n",
    "\n",
    "saveDir = './images1/'\n",
    "# img_vec=torch.tensor([])\n",
    "img_vec=[]\n",
    "photo_combine=[]\n",
    "for picid in pic_id['img']:\n",
    "    #print(picid)\n",
    "    if picid != 'img': \n",
    "        img = load_img(saveDir+str(picid)+'.jpg')\n",
    "        \n",
    "        #img = img.convert(\"RGBA\")\n",
    "        img = img.resize((32, 32))\n",
    "        #顯示圖片\n",
    "        #img.show()\n",
    "        #將圖片轉換為陣列形式，元素為其畫素的亮度值\n",
    "        img_vec.append(np.asarray(img, dtype=np.float32))\n",
    "\n",
    "\n",
    "img_vec=np.array(img_vec)\n",
    "    \n",
    "x2_train, x2_test, y2_train, y2_test = train_test_split(img_vec, viewcount, test_size=0.35)\n",
    "x2_train=np.array(x2_train)\n",
    "x2_test=np.array(x2_test)\n",
    "x2_train = x2_train.reshape(x2_train.shape[0],32,32,3).astype('float32')#可以不用轉\n",
    "x2_test = x2_test.reshape(x2_test.shape[0],32,32,3).astype('float32')\n",
    "y2_train=np.array(y2_train)\n",
    "y2_test=np.array(y2_test)\n",
    "x2_train_normalize=x2_train/255.0\n",
    "x2_test_normalize=x2_test/255.0\n",
    "\n",
    "x2_train_normalize=tf.convert_to_tensor(x2_train_normalize)\n",
    "x2_test_normalize=tf.convert_to_tensor(x2_test_normalize)\n",
    "     \n",
    "\n",
    "#photo model\n",
    "model_photo=Sequential()\n",
    "\n",
    "model_photo.add(Conv2D(filters=32,  #隨機產生32個filter weight\n",
    "                 kernel_size=(3,3), #濾鏡大小3X3\n",
    "                 padding='same',  #設定卷積運算，產生的卷積影像大小相同\n",
    "                 input_shape=(32,32,3),  #輸入影像32X32，RGB3原色\n",
    "                 activation='relu')) #ReLU激活函數\n",
    "\n",
    "\n",
    "model_photo.add(Dropout(0.25))  #每次迭代，隨機丟棄 25% 神經元\n",
    "\n",
    "model_photo.add(MaxPooling2D(pool_size=(2, 2))) #將32X32影像，縮小成16X16的影像\n",
    "\n",
    "\n",
    "model_photo.add(Conv2D(filters=64,  #隨機產生64個filter weight\n",
    "                 kernel_size=(3,3), #濾鏡大小3X3\n",
    "                 padding='same', #設定卷積運算，產生的卷積影像大小相同\n",
    "                 activation='relu'))#ReLU激活函數\n",
    "\n",
    "model_photo.add(Dropout(0.25)) #每次迭代，隨機丟棄 25% 神經元\n",
    "\n",
    "model_photo.add(MaxPooling2D(pool_size=(2, 2)))  #將16X16影像，縮小成8X8的影像\n",
    "\n",
    "model_photo.add(Flatten())  #池化層2的64個8X8影像轉為一維向量=>64X8X8=4096(個神經元)\n",
    "model_photo.add(Dropout(0.25))#隨機丟棄 25% 神經元\n",
    "model_photo.add(Dense(1, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "# final_model = Model(model_photo.input,model_photo.output)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 23,489\n",
      "Trainable params: 23,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "59/59 [==============================] - 7s 106ms/step - loss: 0.7042 - accuracy: 0.4971 - val_loss: 0.6910 - val_accuracy: 0.4914\n",
      "Epoch 2/10\n",
      "59/59 [==============================] - 6s 100ms/step - loss: 0.6904 - accuracy: 0.4737 - val_loss: 0.6876 - val_accuracy: 0.4914\n",
      "Epoch 3/10\n",
      "59/59 [==============================] - 6s 105ms/step - loss: 0.6828 - accuracy: 0.4909 - val_loss: 0.6865 - val_accuracy: 0.4914\n",
      "Epoch 4/10\n",
      "59/59 [==============================] - 6s 109ms/step - loss: 0.6775 - accuracy: 0.4880 - val_loss: 0.6891 - val_accuracy: 0.4914\n",
      "Epoch 5/10\n",
      "59/59 [==============================] - 6s 103ms/step - loss: 0.6786 - accuracy: 0.4864 - val_loss: 0.6873 - val_accuracy: 0.4914\n",
      "Epoch 6/10\n",
      "59/59 [==============================] - 6s 100ms/step - loss: 0.6744 - accuracy: 0.4898 - val_loss: 0.6832 - val_accuracy: 0.4914\n",
      "Epoch 7/10\n",
      "59/59 [==============================] - 6s 104ms/step - loss: 0.6551 - accuracy: 0.4841 - val_loss: 0.6812 - val_accuracy: 0.4914\n",
      "Epoch 8/10\n",
      "59/59 [==============================] - 6s 103ms/step - loss: 0.6551 - accuracy: 0.4726 - val_loss: 0.6829 - val_accuracy: 0.4914\n",
      "Epoch 9/10\n",
      "59/59 [==============================] - 6s 110ms/step - loss: 0.6507 - accuracy: 0.4868 - val_loss: 0.6827 - val_accuracy: 0.4914\n",
      "Epoch 10/10\n",
      "59/59 [==============================] - 7s 111ms/step - loss: 0.6353 - accuracy: 0.4719 - val_loss: 0.6884 - val_accuracy: 0.4914\n",
      "1/1 [==============================] - 1s 854ms/step - loss: 0.6502 - accuracy: 0.4850\n",
      "1/1 [==============================] - 1s 509ms/step - loss: 0.6884 - accuracy: 0.4914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x201c39fc550>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "   \n",
    "model_photo.summary()\n",
    "\n",
    "model_photo.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "# 'sparse_categorical_crossentropy'\n",
    "\n",
    "\n",
    "train_history = model_photo.fit(x2_train_normalize,y2_train, batch_size=64, epochs = 10, verbose=1,validation_data=(x2_test_normalize,y2_test))\n",
    "y_pred = np.round(model_photo.predict(x2_test_normalize,steps=1))\n",
    "\n",
    "# s=final_model.evaluate([x1_train, x2_train_normalize], sum_vector,verbose=1,steps=1)\n",
    "# print(\"Accuracy of train:\", s[1])\n",
    "scores = model_photo.evaluate(x2_train_normalize, y2_train,verbose=1,steps=1)\n",
    "# print(\"Accuracy:\"+str(scores[1]))\n",
    "\n",
    "# y2_test=np.argmax(y2_test, axis=1)\n",
    "\n",
    "scores=model_photo.evaluate(x2_test_normalize,y2_test,verbose=1,steps=1)\n",
    "\n",
    "plt.plot(train_history.history['accuracy'])\n",
    "plt.plot(train_history.history['loss'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
