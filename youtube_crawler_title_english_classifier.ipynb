{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "# !pip install gputil\n",
    "# try:\n",
    "#   import GPUtil as GPU\n",
    "#   GPUs = GPU.getGPUs()\n",
    "#   device='/gpu:0'\n",
    "# except:\n",
    "#   device='/cpu:0'\n",
    "\n",
    "# import os\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "\n",
    "# # ##出現提示欄進行授權\n",
    "\n",
    "# os.chdir('/content/drive/Shareddrives/專題') #切換該目錄\n",
    "# os.listdir() #確認目錄內容\n",
    "# !pip install zhon\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re \n",
    "import cv2\n",
    "import keras\n",
    "import keras.utils\n",
    "from keras import utils as np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import cifar10 #匯入cifar10資料集\n",
    "import numpy as np #匯入numpy模組\n",
    "np.random.seed(10) #設定seed\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential  #匯入Sequential模組\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Dense,Dropout,Flatten,Conv2D,Conv1D,MaxPooling2D,MaxPooling1D  #匯入layers模組\n",
    "from keras.layers import ZeroPadding2D,Activation  #匯入layers模組\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, concatenate,Embedding,Layer,Multiply \n",
    "import tensorflow as tf\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.recurrent import LSTM\n",
    "from sklearn.metrics import accuracy_score\n",
    "from zhon.hanzi import punctuation\n",
    "import jieba\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow.keras.backend as K\n",
    "from keras import metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras import optimizers\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import random\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "embedding_matrix=np.load('gensim_word2vec_english.npy')\n",
    "# title_LSTMmodel = load_model(\"title_LSTMmodel.h5\")\n",
    "# title_RNNmodel = load_model(\"title_RNNmodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5806\n"
     ]
    }
   ],
   "source": [
    "class attention(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(attention,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        self.W=self.add_weight(name=\"att_weight\",shape=(input_shape[-1],1),initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\",shape=(input_shape[1],1),initializer=\"zeros\")        \n",
    "        super(attention, self).build(input_shape)\n",
    "\n",
    "    def call(self,x):\n",
    "        et=K.squeeze(K.tanh(K.dot(x,self.W)+self.b),axis=-1)\n",
    "        at=K.softmax(et)\n",
    "        at=K.expand_dims(at,axis=-1)\n",
    "        output=x*at\n",
    "        return K.sum(output,axis=1)\n",
    "\n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return (input_shape[0],input_shape[-1])\n",
    "\n",
    "    def get_config(self):\n",
    "        return super(attention,self).get_config()\n",
    "    \n",
    "\n",
    "def get_dataset_partitions_tf(dsx, dsy, ds_size):\n",
    "    #assert (train_split + test_split + val_split) == 1\n",
    "    \n",
    "        # Specify seed to always have the same split distribution between runs\n",
    "    dsx, dsy=shuffle(dsx, dsy)\n",
    "\n",
    "    train_size = int(0.65* ds_size)\n",
    "    val_size = int(0.1 * ds_size)\n",
    "    \n",
    "\n",
    "    train_dsx = dsx[:train_size]\n",
    "    val_dsx = dsx[train_size:val_size]\n",
    "    test_dsx = dsx[val_size:]\n",
    "    \n",
    "    train_dsy = dsy[:train_size]\n",
    "    val_dsy = dsy[train_size:val_size]\n",
    "    test_dsy = dsy[val_size:]\n",
    "    \n",
    "#     train_ds = ds.take(train_size)\n",
    "#     val_ds = ds.skip(train_size).take(val_size)\n",
    "#     test_ds = ds.skip(train_size).skip(val_size)\n",
    "    \n",
    "    return train_dsx, val_dsx, test_dsx, train_dsy, val_dsy, test_dsy\n",
    "\n",
    "\n",
    "X = pd.read_csv(\"concat_data_english.csv\",encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "viewcount=X[\"classifier_2\"]\n",
    "# viewcount=X.iloc[:,6:26]\n",
    "print(len(viewcount))\n",
    "#title = list(X.iloc[:,2])\n",
    "\n",
    "# for i in range(len(viewcount)):\n",
    "#     X[\"title\"][i]=str(X[\"title\"][i])\n",
    "# for j in range(len(viewcount)):\n",
    "#     X[\"title\"][j] = X[\"title\"][j].replace(r'[^\\w\\s]+', '')\n",
    "#     punctuation_str = punctuation\n",
    "#     punct = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{}~| '\n",
    "#     for i in punctuation:\n",
    "#         X[\"title\"][j] = X[\"title\"][j].replace(i, '')\n",
    "#     for i in punct:\n",
    "#         X[\"title\"][j] = X[\"title\"][j].replace(i, '')\n",
    "        \n",
    "#     seg_list = list(jieba.cut(X[\"title\"][j], cut_all=False))\n",
    "\n",
    "# seg_list=[]\n",
    "# for i in range(len(X[\"new_title\"])):\n",
    "#     seg_list.append(list(jieba.cut(X[\"new_title\"][i], cut_all=False)))\n",
    "\n",
    "token = Tokenizer(num_words=4000) \n",
    "token.fit_on_texts(X[\"new_title\"])\n",
    "x_list_seq = token.texts_to_sequences(X[\"new_title\"])\n",
    "#x_test_seq = token.texts_to_sequences(x_test)\n",
    "x_list = sequence.pad_sequences(x_list_seq, maxlen=30)\n",
    "word_index = token.word_index #{'天氣':1,'氣溫':2}\n",
    "#x_test = sequence.pad_sequences(x_test_seq, maxlen=380)\n",
    "\n",
    "# viewcount = tf.keras.utils.to_categorical(np.asarray(viewcount))\n",
    "\n",
    "VALIDATION_SPLIT=0.25\n",
    "indices = np.arange(x_list.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "x_list = x_list[indices]\n",
    "viewcount = viewcount[indices]\n",
    "nb_validation_samples = int(VALIDATION_SPLIT * x_list.shape[0])\n",
    "\n",
    "x1_train = x_list[:-nb_validation_samples]\n",
    "y1_train = viewcount[:-nb_validation_samples]\n",
    "x1_test = x_list[-nb_validation_samples:]\n",
    "y1_test = viewcount[-nb_validation_samples:]\n",
    "\n",
    "\n",
    "\n",
    "# # X, y = shuffle(x_list, viewcount)\n",
    "# # x1_train, x1_test, y1_train, y1_test = train_test_split(X, y, test_size=0.35)\n",
    "\n",
    "# # x1_train, x1_val, x1_test, y1_train, y1_val, y1_test=get_dataset_partitions_tf(x_list, viewcount, len(x_list))\n",
    "# # x1_train, x1_val, x1_test=get_dataset_partitions_tf(x_list,len(x_list))\n",
    "# # y1_train, y1_val, y1_test=get_dataset_partitions_tf(viewcount,len(viewcount))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# x1_train, y1_train = shuffle(x1_train, y1_train, random_state=0)\n",
    "# x1_test, y1_test = shuffle(x1_test, y1_test, random_state=0)\n",
    "# # x1_train = tf.convert_to_tensor(x1_train)\n",
    "# # x1_test = tf.convert_to_tensor(x1_test)\n",
    "     \n",
    "#title model    \n",
    "max_features = 3922 #5396 #5738 #6849 #144721 #208468 #1208971\n",
    "max_length = 30 \n",
    "embedding_size = 100 \n",
    "lstm_output_size = 128 \n",
    "batch_size = 2 \n",
    "epochs = 2 \n",
    "\n",
    "model_title = Sequential()\n",
    "model_title.add(Embedding ( input_dim = max_features, \n",
    "                       output_dim = embedding_size, \n",
    "                       weights= [embedding_matrix] , input_length = max_length ))\n",
    "model_title.add(Conv1D(100, 2, padding='same', activation='relu'))\n",
    "# model_title.add(Dropout(0.25))\n",
    "model_title.add(MaxPooling1D(pool_size=2))\n",
    "model_title.add(Conv1D(200, 3, padding='same', activation='relu'))\n",
    "# model_title.add(Dropout(0.25))\n",
    "model_title.add(MaxPooling1D(pool_size=2))\n",
    "model_title.add(Conv1D(200, 4, padding='same', activation='relu'))\n",
    "# model_title.add(Dropout(0.25))\n",
    "model_title.add(MaxPooling1D(pool_size=2))\n",
    "model_title.add(Flatten())\n",
    "model_title.add(Dropout(0.25))\n",
    "model_title.add(Dense(250, activation='relu'))\n",
    "model_title.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    \n",
    "# model_title = Sequential()\n",
    "# model_title.add ( Embedding ( input_dim = max_features, \n",
    "#                        output_dim = embedding_size, \n",
    "#                        weights= [embedding_matrix] , input_length = max_length ) ) \n",
    "# model_title.add ( Dropout ( 0.25 ) ) \n",
    "# model_title.add ( LSTM ( embedding_size , return_sequences = True , dropout = 0.2 , recurrent_dropout = 0.2 ) ) \n",
    "# model_title.add ( LSTM ( lstm_output_size , dropout = 0.2 , recurrent_dropout = 0.2 ) )     \n",
    "# model_title.add(Dense(100,activation='sigmoid',trainable=True))\n",
    "\n",
    "# inputs=Input((max_length,))\n",
    "\n",
    "# model_title.add(Embedding ( input_dim = max_features, \n",
    "#                        output_dim = embedding_size, \n",
    "#                        weights= [embedding_matrix] , input_length = max_length ))\n",
    "# model_title.add(LSTM ( embedding_size , return_sequences = True , dropout = 0.2 , recurrent_dropout = 0.2 ))\n",
    "# model_title.add(attention())\n",
    "# # model_title.add(Dense(20,activation='sigmoid',trainable=True))\n",
    "\n",
    "# model_title.add(Dense(20,activation='softmax',trainable=True))\n",
    "\n",
    "\n",
    "\n",
    "# final_model = Dense(64)(model_title) #原始的全连接\n",
    "\n",
    "\n",
    "# final_model = Dense(10,activation='sigmoid',trainable=True)(final_model)\n",
    "# final_model = Dense(1, activation='sigmoid')(model_title)\n",
    "\n",
    "# final_model = Model(model_title.input, model_title.output)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (None, 30, 100)           392200    \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 30, 100)           20100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 15, 100)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 15, 200)           60200     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 7, 200)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 7, 200)            160200    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 3, 200)            0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 250)               150250    \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 783,201\n",
      "Trainable params: 783,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "35/35 [==============================] - 3s 51ms/step - loss: 11.3358 - accuracy: 0.4835 - val_loss: 0.6800 - val_accuracy: 0.5844\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - 1s 37ms/step - loss: 0.6690 - accuracy: 0.6079 - val_loss: 0.6623 - val_accuracy: 0.5824\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - 1s 37ms/step - loss: 0.5971 - accuracy: 0.6892 - val_loss: 0.6781 - val_accuracy: 0.6389\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - 1s 37ms/step - loss: 0.6188 - accuracy: 0.7361 - val_loss: 0.6751 - val_accuracy: 0.6389\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - 1s 38ms/step - loss: 0.3764 - accuracy: 0.8337 - val_loss: 1.0646 - val_accuracy: 0.6361\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - 1s 37ms/step - loss: 0.3029 - accuracy: 0.8767 - val_loss: 1.3146 - val_accuracy: 0.6389\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - 1s 38ms/step - loss: 0.2813 - accuracy: 0.8934 - val_loss: 1.0792 - val_accuracy: 0.6506\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - 1s 37ms/step - loss: 0.2021 - accuracy: 0.9225 - val_loss: 1.8192 - val_accuracy: 0.6554\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - 1s 38ms/step - loss: 0.1686 - accuracy: 0.9410 - val_loss: 1.4756 - val_accuracy: 0.6368\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - 1s 38ms/step - loss: 0.1638 - accuracy: 0.9305 - val_loss: 1.6180 - val_accuracy: 0.6506\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.1472 - accuracy: 0.9387\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.6180 - accuracy: 0.6506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x19fc6808700>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_title.summary()\n",
    "opt = tf.keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "sgd = optimizers.SGD(lr=0.001)\n",
    "model_title.compile(loss = 'binary_crossentropy', optimizer=opt,metrics = ['accuracy'])\n",
    "# sparse_categorical_crossentropy\n",
    "\n",
    "history=model_title.fit(x1_train,y1_train, batch_size=128, epochs = 10, validation_data=(x1_test,y1_test),verbose=1)\n",
    "s=model_title.evaluate(x1_train, y1_train, batch_size=128, verbose=1)\n",
    "y_pred=model_title.predict(x1_test)\n",
    "test_s = model_title.evaluate(x1_test, y1_test, batch_size=128, verbose=1)\n",
    "# print(accuracy_score(y1_test,y_pred))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
